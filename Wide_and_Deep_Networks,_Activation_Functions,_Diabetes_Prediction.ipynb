{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wide and Deep Networks, Activation Functions, Diabetes Prediction.ipynb",
      "provenance": [],
      "mount_file_id": "1AOT7SA2PrQKzckcDrhZcS03ixP95yuYN",
      "authorship_tag": "ABX9TyON/tkp4560bzggKtS4vSGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mindyng/ML-Keeping-it-FRESH/blob/master/Wide_and_Deep_Networks%2C_Activation_Functions%2C_Diabetes_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgdenHED92th",
        "outputId": "4696982b-ccfb-4a63-caaa-a9066a5abce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Mount Drive in order to load in diabetes data\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIlxYkbd7ffe",
        "outputId": "6ac75e82-7551-47b7-90ad-c7c80967a864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch import nn, optim, from_numpy\n",
        "import numpy as np\n",
        "\n",
        "xy = np.loadtxt('/content/drive/My Drive/diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = from_numpy(xy[:, 0:-1])\n",
        "y_data = from_numpy(xy[:, [-1]])\n",
        "print(f'X\\'s shape: {x_data.shape} | Y\\'s shape: {y_data.shape}')\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = nn.Linear(8, 6)\n",
        "        self.l2 = nn.Linear(6, 4)\n",
        "        self.l3 = nn.Linear(4, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# our model\n",
        "model = Model()\n",
        "\n",
        "\n",
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "criterion = nn.BCELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(f'Epoch: {epoch + 1}/100 | Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n",
            "Epoch: 1/100 | Loss: 0.7922\n",
            "Epoch: 2/100 | Loss: 0.7786\n",
            "Epoch: 3/100 | Loss: 0.7662\n",
            "Epoch: 4/100 | Loss: 0.7550\n",
            "Epoch: 5/100 | Loss: 0.7448\n",
            "Epoch: 6/100 | Loss: 0.7355\n",
            "Epoch: 7/100 | Loss: 0.7271\n",
            "Epoch: 8/100 | Loss: 0.7195\n",
            "Epoch: 9/100 | Loss: 0.7126\n",
            "Epoch: 10/100 | Loss: 0.7063\n",
            "Epoch: 11/100 | Loss: 0.7007\n",
            "Epoch: 12/100 | Loss: 0.6955\n",
            "Epoch: 13/100 | Loss: 0.6909\n",
            "Epoch: 14/100 | Loss: 0.6866\n",
            "Epoch: 15/100 | Loss: 0.6828\n",
            "Epoch: 16/100 | Loss: 0.6793\n",
            "Epoch: 17/100 | Loss: 0.6762\n",
            "Epoch: 18/100 | Loss: 0.6733\n",
            "Epoch: 19/100 | Loss: 0.6707\n",
            "Epoch: 20/100 | Loss: 0.6684\n",
            "Epoch: 21/100 | Loss: 0.6662\n",
            "Epoch: 22/100 | Loss: 0.6643\n",
            "Epoch: 23/100 | Loss: 0.6625\n",
            "Epoch: 24/100 | Loss: 0.6609\n",
            "Epoch: 25/100 | Loss: 0.6595\n",
            "Epoch: 26/100 | Loss: 0.6582\n",
            "Epoch: 27/100 | Loss: 0.6570\n",
            "Epoch: 28/100 | Loss: 0.6559\n",
            "Epoch: 29/100 | Loss: 0.6549\n",
            "Epoch: 30/100 | Loss: 0.6540\n",
            "Epoch: 31/100 | Loss: 0.6532\n",
            "Epoch: 32/100 | Loss: 0.6524\n",
            "Epoch: 33/100 | Loss: 0.6518\n",
            "Epoch: 34/100 | Loss: 0.6512\n",
            "Epoch: 35/100 | Loss: 0.6506\n",
            "Epoch: 36/100 | Loss: 0.6501\n",
            "Epoch: 37/100 | Loss: 0.6496\n",
            "Epoch: 38/100 | Loss: 0.6492\n",
            "Epoch: 39/100 | Loss: 0.6488\n",
            "Epoch: 40/100 | Loss: 0.6485\n",
            "Epoch: 41/100 | Loss: 0.6482\n",
            "Epoch: 42/100 | Loss: 0.6479\n",
            "Epoch: 43/100 | Loss: 0.6476\n",
            "Epoch: 44/100 | Loss: 0.6474\n",
            "Epoch: 45/100 | Loss: 0.6471\n",
            "Epoch: 46/100 | Loss: 0.6469\n",
            "Epoch: 47/100 | Loss: 0.6468\n",
            "Epoch: 48/100 | Loss: 0.6466\n",
            "Epoch: 49/100 | Loss: 0.6464\n",
            "Epoch: 50/100 | Loss: 0.6463\n",
            "Epoch: 51/100 | Loss: 0.6462\n",
            "Epoch: 52/100 | Loss: 0.6461\n",
            "Epoch: 53/100 | Loss: 0.6460\n",
            "Epoch: 54/100 | Loss: 0.6459\n",
            "Epoch: 55/100 | Loss: 0.6458\n",
            "Epoch: 56/100 | Loss: 0.6457\n",
            "Epoch: 57/100 | Loss: 0.6456\n",
            "Epoch: 58/100 | Loss: 0.6455\n",
            "Epoch: 59/100 | Loss: 0.6455\n",
            "Epoch: 60/100 | Loss: 0.6454\n",
            "Epoch: 61/100 | Loss: 0.6454\n",
            "Epoch: 62/100 | Loss: 0.6453\n",
            "Epoch: 63/100 | Loss: 0.6453\n",
            "Epoch: 64/100 | Loss: 0.6453\n",
            "Epoch: 65/100 | Loss: 0.6452\n",
            "Epoch: 66/100 | Loss: 0.6452\n",
            "Epoch: 67/100 | Loss: 0.6452\n",
            "Epoch: 68/100 | Loss: 0.6451\n",
            "Epoch: 69/100 | Loss: 0.6451\n",
            "Epoch: 70/100 | Loss: 0.6451\n",
            "Epoch: 71/100 | Loss: 0.6451\n",
            "Epoch: 72/100 | Loss: 0.6450\n",
            "Epoch: 73/100 | Loss: 0.6450\n",
            "Epoch: 74/100 | Loss: 0.6450\n",
            "Epoch: 75/100 | Loss: 0.6450\n",
            "Epoch: 76/100 | Loss: 0.6450\n",
            "Epoch: 77/100 | Loss: 0.6450\n",
            "Epoch: 78/100 | Loss: 0.6450\n",
            "Epoch: 79/100 | Loss: 0.6449\n",
            "Epoch: 80/100 | Loss: 0.6449\n",
            "Epoch: 81/100 | Loss: 0.6449\n",
            "Epoch: 82/100 | Loss: 0.6449\n",
            "Epoch: 83/100 | Loss: 0.6449\n",
            "Epoch: 84/100 | Loss: 0.6449\n",
            "Epoch: 85/100 | Loss: 0.6449\n",
            "Epoch: 86/100 | Loss: 0.6449\n",
            "Epoch: 87/100 | Loss: 0.6449\n",
            "Epoch: 88/100 | Loss: 0.6449\n",
            "Epoch: 89/100 | Loss: 0.6449\n",
            "Epoch: 90/100 | Loss: 0.6449\n",
            "Epoch: 91/100 | Loss: 0.6449\n",
            "Epoch: 92/100 | Loss: 0.6449\n",
            "Epoch: 93/100 | Loss: 0.6449\n",
            "Epoch: 94/100 | Loss: 0.6449\n",
            "Epoch: 95/100 | Loss: 0.6449\n",
            "Epoch: 96/100 | Loss: 0.6449\n",
            "Epoch: 97/100 | Loss: 0.6449\n",
            "Epoch: 98/100 | Loss: 0.6448\n",
            "Epoch: 99/100 | Loss: 0.6448\n",
            "Epoch: 100/100 | Loss: 0.6448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NioLH7Fo-zWF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}