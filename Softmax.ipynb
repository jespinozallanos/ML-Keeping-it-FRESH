{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Softmax.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUltJrrkMcPqvgyLFRbEGa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d426f87bd73431b9a35e18eb76bfe52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d0549c7106e463e8b9d82ac4ea09169",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dafe9bbc31a64fc39df645092c97c08e",
              "IPY_MODEL_9f66b52bb45645e7b8c8999f7a99276f"
            ]
          }
        },
        "2d0549c7106e463e8b9d82ac4ea09169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dafe9bbc31a64fc39df645092c97c08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d371f00f72304d448dc6eef01a246c9b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad75ce3a448d4bfdb5ae5fb1f141b38a"
          }
        },
        "9f66b52bb45645e7b8c8999f7a99276f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_696d086734a24163bedf19245ef9ef5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 1507047.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9bdcd60360b46859157d656fbe94fcd"
          }
        },
        "d371f00f72304d448dc6eef01a246c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad75ce3a448d4bfdb5ae5fb1f141b38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "696d086734a24163bedf19245ef9ef5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9bdcd60360b46859157d656fbe94fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0dd45f0303144f7949c13e138205c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_153af1a562344defb85e0579cb8685f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ff85373ed9b4951aabce320c75a290f",
              "IPY_MODEL_ed8accbc94be44d49bc0b8f04f76a092"
            ]
          }
        },
        "153af1a562344defb85e0579cb8685f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ff85373ed9b4951aabce320c75a290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_138e0a9e3aef4650bc0b37398ebd623e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f5da624931a4c9d8167af72c448fc85"
          }
        },
        "ed8accbc94be44d49bc0b8f04f76a092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92fe02064b4f41b695a74dc52e5c5c33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:01&lt;00:00, 29648.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80beb48469ab4a90889dc9cf9e2376cc"
          }
        },
        "138e0a9e3aef4650bc0b37398ebd623e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f5da624931a4c9d8167af72c448fc85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92fe02064b4f41b695a74dc52e5c5c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80beb48469ab4a90889dc9cf9e2376cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67484c7f279d4f4facfe5ab5b7ac90a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fe8dbfae05649f1b0eafabb41b2167f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f139ca879b8a4d01a63fe60622dcd69e",
              "IPY_MODEL_ada0cfe0cf7e436096be120b3a21e1e5"
            ]
          }
        },
        "9fe8dbfae05649f1b0eafabb41b2167f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f139ca879b8a4d01a63fe60622dcd69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2304d7f7bff4bbaa735b2bc47418a79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ef31642a9b64e2ab52391e3b31eb399"
          }
        },
        "ada0cfe0cf7e436096be120b3a21e1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9242dd3597ba47a8bfb685a74631b584",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:00&lt;00:00, 2125573.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0982d7c618934b63b24e46c5b049d481"
          }
        },
        "c2304d7f7bff4bbaa735b2bc47418a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ef31642a9b64e2ab52391e3b31eb399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9242dd3597ba47a8bfb685a74631b584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0982d7c618934b63b24e46c5b049d481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "edd28dec44414fa7aa09a980ccc51531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b130e670a2749899deb460dcf75a550",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6922406ab6524fbe8ac477b13e1a1506",
              "IPY_MODEL_e454aacd72154002bfc299961ba13301"
            ]
          }
        },
        "8b130e670a2749899deb460dcf75a550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6922406ab6524fbe8ac477b13e1a1506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_864d893f06a94dca8107da0f40487b98",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_043a22312d8c41e282eede42bd0e574e"
          }
        },
        "e454aacd72154002bfc299961ba13301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b59d1d1124a6446c8f740f42f5364572",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8edb76f0630243269ac0d087947594f3"
          }
        },
        "864d893f06a94dca8107da0f40487b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "043a22312d8c41e282eede42bd0e574e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b59d1d1124a6446c8f740f42f5364572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8edb76f0630243269ac0d087947594f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mindyng/ML-Keeping-it-FRESH/blob/master/Softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5k6XMgeb6uq"
      },
      "source": [
        "Essentially, from linear regression equation outputs, Softmax classifier function is used to transform these outputs into positive values (percentages) that all sum up into 1. This is so that cross-entropy loss can then be applied. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptxDCBjziVMO"
      },
      "source": [
        "## Softmax Classification Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhUODezebxSb",
        "outputId": "6ca6645e-f7d7-4824-810d-943378dbf239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from torch import nn, tensor, max\n",
        "import numpy as np\n",
        "\n",
        "# Cross entropy example\n",
        "# One hot\n",
        "# 0: 1 0 0\n",
        "# 1: 0 1 0\n",
        "# 2: 0 0 1\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred1 = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred2 = np.array([0.1, 0.3, 0.6])\n",
        "print(f'Loss1: {np.sum(-Y * np.log(Y_pred1)):.4f}')\n",
        "print(f'Loss2: {np.sum(-Y * np.log(Y_pred2)):.4f}')\n",
        "\n",
        "# Softmax + CrossEntropy (logSoftmax + NLLLoss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = tensor([0], requires_grad=False)\n",
        "\n",
        "# input is of size nBatch x nClasses = 1 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred2 = tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f} \\nPyTorch Loss2: {l2.item():.4f}')\n",
        "print(f'Y_pred1: {max(Y_pred1.data, 1)[1].item()}')\n",
        "print(f'Y_pred2: {max(Y_pred2.data, 1)[1].item()}')\n",
        "\n",
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = tensor([2, 0, 1], requires_grad=False)\n",
        "\n",
        "# input is of size nBatch x nClasses = 2 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = tensor([[0.1, 0.2, 0.9],\n",
        "                  [1.1, 0.1, 0.2],\n",
        "                  [0.2, 2.1, 0.1]])\n",
        "\n",
        "Y_pred2 = tensor([[0.8, 0.2, 0.3],\n",
        "                  [0.2, 0.3, 0.5],\n",
        "                  [0.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f} \\nBatch Loss2: {l2.data:.4f}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss1: 0.3567\n",
            "Loss2: 2.3026\n",
            "PyTorch Loss1: 0.4170 \n",
            "PyTorch Loss2: 1.8406\n",
            "Y_pred1: 0\n",
            "Y_pred2: 1\n",
            "Batch Loss1:  0.4966 \n",
            "Batch Loss2: 1.2389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw_Ykj3FiYLw"
      },
      "source": [
        "## Softmax Classification with MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7vQq4W7iAHG",
        "outputId": "dc620248-57ff-430b-8df1-569bf81f2f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1d426f87bd73431b9a35e18eb76bfe52",
            "2d0549c7106e463e8b9d82ac4ea09169",
            "dafe9bbc31a64fc39df645092c97c08e",
            "9f66b52bb45645e7b8c8999f7a99276f",
            "d371f00f72304d448dc6eef01a246c9b",
            "ad75ce3a448d4bfdb5ae5fb1f141b38a",
            "696d086734a24163bedf19245ef9ef5f",
            "e9bdcd60360b46859157d656fbe94fcd",
            "e0dd45f0303144f7949c13e138205c12",
            "153af1a562344defb85e0579cb8685f4",
            "0ff85373ed9b4951aabce320c75a290f",
            "ed8accbc94be44d49bc0b8f04f76a092",
            "138e0a9e3aef4650bc0b37398ebd623e",
            "1f5da624931a4c9d8167af72c448fc85",
            "92fe02064b4f41b695a74dc52e5c5c33",
            "80beb48469ab4a90889dc9cf9e2376cc",
            "67484c7f279d4f4facfe5ab5b7ac90a1",
            "9fe8dbfae05649f1b0eafabb41b2167f",
            "f139ca879b8a4d01a63fe60622dcd69e",
            "ada0cfe0cf7e436096be120b3a21e1e5",
            "c2304d7f7bff4bbaa735b2bc47418a79",
            "8ef31642a9b64e2ab52391e3b31eb399",
            "9242dd3597ba47a8bfb685a74631b584",
            "0982d7c618934b63b24e46c5b049d481",
            "edd28dec44414fa7aa09a980ccc51531",
            "8b130e670a2749899deb460dcf75a550",
            "6922406ab6524fbe8ac477b13e1a1506",
            "e454aacd72154002bfc299961ba13301",
            "864d893f06a94dca8107da0f40487b98",
            "043a22312d8c41e282eede42bd0e574e",
            "b59d1d1124a6446c8f740f42f5364572",
            "8edb76f0630243269ac0d087947594f3"
          ]
        }
      },
      "source": [
        "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "from __future__ import print_function\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "# Training settings\n",
        "batch_size = 64\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520)\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).item()\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 10):\n",
        "        epoch_start = time.time()\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "    m, s = divmod(time.time() - since, 60)\n",
        "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MNIST Model on cpu\n",
            "============================================\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d426f87bd73431b9a35e18eb76bfe52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0dd45f0303144f7949c13e138205c12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67484c7f279d4f4facfe5ab5b7ac90a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edd28dec44414fa7aa09a980ccc51531",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.308158\n",
            "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.291844\n",
            "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.303957\n",
            "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.315926\n",
            "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.295573\n",
            "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.302736\n",
            "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.300162\n",
            "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.290815\n",
            "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.304819\n",
            "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.289838\n",
            "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.297209\n",
            "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.300118\n",
            "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.298135\n",
            "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.302113\n",
            "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.296250\n",
            "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.292796\n",
            "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.299088\n",
            "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.308477\n",
            "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.301058\n",
            "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.290304\n",
            "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.296355\n",
            "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.298907\n",
            "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.298185\n",
            "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.303467\n",
            "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.297621\n",
            "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.298704\n",
            "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.299620\n",
            "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.291801\n",
            "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.285450\n",
            "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.292922\n",
            "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.285424\n",
            "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.292097\n",
            "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.292253\n",
            "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.294849\n",
            "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.296228\n",
            "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.295124\n",
            "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.288854\n",
            "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.290329\n",
            "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.301649\n",
            "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.288343\n",
            "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.301815\n",
            "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.291720\n",
            "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.284073\n",
            "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.296760\n",
            "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.290932\n",
            "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.285298\n",
            "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.283330\n",
            "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.286326\n",
            "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.290765\n",
            "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.286312\n",
            "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.285286\n",
            "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.281558\n",
            "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.289970\n",
            "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.282174\n",
            "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.275988\n",
            "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.285033\n",
            "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.283101\n",
            "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.279432\n",
            "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.276278\n",
            "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.267510\n",
            "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.269772\n",
            "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.264634\n",
            "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.273925\n",
            "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.267180\n",
            "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.268951\n",
            "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.252165\n",
            "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.263406\n",
            "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.256862\n",
            "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.255548\n",
            "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.253141\n",
            "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.241452\n",
            "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.266155\n",
            "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.253999\n",
            "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.245310\n",
            "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.233736\n",
            "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.216776\n",
            "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.221475\n",
            "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.221500\n",
            "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.201929\n",
            "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.206127\n",
            "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.176955\n",
            "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.193357\n",
            "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.177329\n",
            "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.143374\n",
            "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 2.137495\n",
            "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.160384\n",
            "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 2.069515\n",
            "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 2.023067\n",
            "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 2.059229\n",
            "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 2.011844\n",
            "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 2.048625\n",
            "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 2.016991\n",
            "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.947937\n",
            "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.983790\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0301, Accuracy: 4296/10000 (43%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.909085\n",
            "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.847837\n",
            "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.855374\n",
            "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.752891\n",
            "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.743329\n",
            "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.807105\n",
            "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.615658\n",
            "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.639071\n",
            "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.484952\n",
            "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.429144\n",
            "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.465021\n",
            "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.368403\n",
            "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.265400\n",
            "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.444850\n",
            "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.264575\n",
            "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 1.209566\n",
            "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.148237\n",
            "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 1.064356\n",
            "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.074662\n",
            "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 1.019124\n",
            "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.973385\n",
            "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.861880\n",
            "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 1.088017\n",
            "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.830433\n",
            "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.710992\n",
            "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 1.095653\n",
            "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.770801\n",
            "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.996683\n",
            "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.670946\n",
            "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.834022\n",
            "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.698022\n",
            "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.617223\n",
            "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.623969\n",
            "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 1.029309\n",
            "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.720380\n",
            "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.628435\n",
            "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.641808\n",
            "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.812873\n",
            "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.681552\n",
            "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.563828\n",
            "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.691052\n",
            "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.628051\n",
            "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.740303\n",
            "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.553470\n",
            "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.559071\n",
            "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.552302\n",
            "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.554582\n",
            "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.511859\n",
            "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.575869\n",
            "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.637028\n",
            "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.426148\n",
            "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.942054\n",
            "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.423856\n",
            "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.805908\n",
            "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.623509\n",
            "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.498149\n",
            "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.548295\n",
            "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.525027\n",
            "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.387472\n",
            "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.643870\n",
            "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.517600\n",
            "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.361619\n",
            "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.570028\n",
            "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.444651\n",
            "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.580155\n",
            "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.497308\n",
            "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.724806\n",
            "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.737285\n",
            "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.624768\n",
            "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.582391\n",
            "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.518599\n",
            "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.540338\n",
            "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.317865\n",
            "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.642120\n",
            "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.584119\n",
            "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.542501\n",
            "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.326767\n",
            "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.520970\n",
            "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.395537\n",
            "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.533892\n",
            "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.395744\n",
            "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.334724\n",
            "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.341673\n",
            "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.452588\n",
            "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.475422\n",
            "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.523778\n",
            "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.426122\n",
            "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.403759\n",
            "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.630792\n",
            "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.371288\n",
            "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.574271\n",
            "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.482471\n",
            "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.634968\n",
            "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.554741\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0069, Accuracy: 8663/10000 (87%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.577092\n",
            "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.394806\n",
            "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.606701\n",
            "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.215788\n",
            "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.327143\n",
            "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.274076\n",
            "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.306224\n",
            "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.317017\n",
            "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.334270\n",
            "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.504641\n",
            "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.403313\n",
            "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.661263\n",
            "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.318847\n",
            "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.619902\n",
            "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.238258\n",
            "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.639525\n",
            "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.661509\n",
            "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.349617\n",
            "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.563727\n",
            "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.535531\n",
            "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.545684\n",
            "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.395778\n",
            "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.478907\n",
            "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.323763\n",
            "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.231478\n",
            "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.492233\n",
            "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.374768\n",
            "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.494558\n",
            "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.348899\n",
            "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.356765\n",
            "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.439704\n",
            "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.345196\n",
            "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.549008\n",
            "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.469818\n",
            "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.510263\n",
            "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.342509\n",
            "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.449069\n",
            "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.441730\n",
            "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.236161\n",
            "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.252803\n",
            "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.527051\n",
            "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.554822\n",
            "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.152941\n",
            "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.510450\n",
            "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.249357\n",
            "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.526541\n",
            "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.304372\n",
            "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.310064\n",
            "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.176953\n",
            "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.469330\n",
            "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.301121\n",
            "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.287118\n",
            "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.328172\n",
            "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.326368\n",
            "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.351106\n",
            "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.538293\n",
            "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.401852\n",
            "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.151203\n",
            "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.490273\n",
            "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.360971\n",
            "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.302260\n",
            "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.192510\n",
            "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.160244\n",
            "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.378542\n",
            "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.321338\n",
            "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.245566\n",
            "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.226954\n",
            "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.321799\n",
            "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.335174\n",
            "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.257702\n",
            "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.444714\n",
            "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.192399\n",
            "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.353870\n",
            "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.248383\n",
            "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.306932\n",
            "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.362913\n",
            "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.355751\n",
            "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.247091\n",
            "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.253909\n",
            "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.211989\n",
            "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.413331\n",
            "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.225244\n",
            "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.474545\n",
            "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.262201\n",
            "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.395349\n",
            "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.408942\n",
            "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.252261\n",
            "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.261506\n",
            "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.255542\n",
            "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.350020\n",
            "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.295941\n",
            "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.485284\n",
            "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.214174\n",
            "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.432207\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0054, Accuracy: 8953/10000 (90%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.364188\n",
            "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.393863\n",
            "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.355769\n",
            "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.209597\n",
            "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.359493\n",
            "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.358931\n",
            "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.283625\n",
            "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.177973\n",
            "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.326463\n",
            "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.189174\n",
            "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.263120\n",
            "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.383227\n",
            "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.279101\n",
            "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.290616\n",
            "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.324647\n",
            "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.240919\n",
            "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.316484\n",
            "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.203766\n",
            "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.330220\n",
            "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.471202\n",
            "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.335772\n",
            "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.224621\n",
            "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.449275\n",
            "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.363654\n",
            "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.119281\n",
            "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.452567\n",
            "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.175806\n",
            "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.265703\n",
            "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.465095\n",
            "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.153844\n",
            "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.189314\n",
            "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.226837\n",
            "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.185131\n",
            "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.265792\n",
            "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.136749\n",
            "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.249148\n",
            "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.188555\n",
            "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.372934\n",
            "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.193613\n",
            "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.353906\n",
            "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.299942\n",
            "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.226288\n",
            "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.168930\n",
            "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.364075\n",
            "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.159401\n",
            "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.320536\n",
            "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.469179\n",
            "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.483419\n",
            "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.141341\n",
            "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.352830\n",
            "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.337114\n",
            "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.220610\n",
            "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.289336\n",
            "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.310259\n",
            "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.601312\n",
            "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.286001\n",
            "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.435670\n",
            "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.329350\n",
            "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.252745\n",
            "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.172053\n",
            "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.267951\n",
            "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.474222\n",
            "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.212116\n",
            "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.424878\n",
            "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.469286\n",
            "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.390651\n",
            "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.222509\n",
            "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.213243\n",
            "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.371490\n",
            "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.174848\n",
            "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.214265\n",
            "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.376958\n",
            "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.136645\n",
            "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.228540\n",
            "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.273034\n",
            "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.212432\n",
            "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.350641\n",
            "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.235440\n",
            "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.258318\n",
            "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.255629\n",
            "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.203264\n",
            "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.226697\n",
            "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.282770\n",
            "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.198284\n",
            "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.172745\n",
            "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.137968\n",
            "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.203406\n",
            "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.334335\n",
            "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.212775\n",
            "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.374116\n",
            "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.116239\n",
            "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.127263\n",
            "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.315832\n",
            "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.452385\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0035, Accuracy: 9344/10000 (93%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.139720\n",
            "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.379343\n",
            "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.156019\n",
            "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.082340\n",
            "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.258946\n",
            "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.255360\n",
            "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.239851\n",
            "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.247952\n",
            "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.131302\n",
            "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.184869\n",
            "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.202686\n",
            "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.148786\n",
            "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.243322\n",
            "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.226058\n",
            "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.232971\n",
            "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.095072\n",
            "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.159432\n",
            "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.474050\n",
            "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.185932\n",
            "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.228601\n",
            "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.173525\n",
            "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.149942\n",
            "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.163963\n",
            "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.204560\n",
            "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.191003\n",
            "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.131755\n",
            "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.280164\n",
            "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.300484\n",
            "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.170368\n",
            "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.165039\n",
            "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.241958\n",
            "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.187960\n",
            "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.197466\n",
            "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.229508\n",
            "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.086498\n",
            "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.157572\n",
            "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.133861\n",
            "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.160573\n",
            "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.374148\n",
            "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.102814\n",
            "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.159439\n",
            "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.184374\n",
            "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.164305\n",
            "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.136244\n",
            "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.130410\n",
            "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.205598\n",
            "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.134667\n",
            "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.180181\n",
            "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.310012\n",
            "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.056788\n",
            "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.178656\n",
            "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.229095\n",
            "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.136552\n",
            "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.077325\n",
            "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.119516\n",
            "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.123698\n",
            "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.294972\n",
            "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.124082\n",
            "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.154473\n",
            "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.189663\n",
            "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.425097\n",
            "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.196942\n",
            "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.210422\n",
            "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.279216\n",
            "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.175862\n",
            "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.174438\n",
            "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.254373\n",
            "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.118005\n",
            "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.084958\n",
            "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.134017\n",
            "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.218692\n",
            "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.252351\n",
            "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.130713\n",
            "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.148392\n",
            "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.222534\n",
            "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.196626\n",
            "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.143037\n",
            "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.267416\n",
            "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.184513\n",
            "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.249709\n",
            "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.158363\n",
            "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.114912\n",
            "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.276279\n",
            "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.234564\n",
            "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.268564\n",
            "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.318641\n",
            "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.222583\n",
            "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.235276\n",
            "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.112612\n",
            "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.232964\n",
            "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.120135\n",
            "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.114191\n",
            "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.227724\n",
            "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.186375\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0030, Accuracy: 9453/10000 (95%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.155243\n",
            "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.233880\n",
            "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.073870\n",
            "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.330909\n",
            "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.228658\n",
            "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.206872\n",
            "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.042847\n",
            "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.261427\n",
            "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.325161\n",
            "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.119582\n",
            "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.154469\n",
            "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.041665\n",
            "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.111224\n",
            "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.136374\n",
            "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.132114\n",
            "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.091039\n",
            "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.288915\n",
            "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.237209\n",
            "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.024417\n",
            "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.147988\n",
            "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.155004\n",
            "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.241296\n",
            "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.075280\n",
            "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.168357\n",
            "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.286323\n",
            "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.256459\n",
            "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.173396\n",
            "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.085771\n",
            "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.184659\n",
            "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.251991\n",
            "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.142965\n",
            "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.404366\n",
            "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.153519\n",
            "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.217307\n",
            "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.134388\n",
            "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.081009\n",
            "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.214678\n",
            "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.217625\n",
            "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.131046\n",
            "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.197068\n",
            "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.080073\n",
            "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.259971\n",
            "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.143683\n",
            "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.161247\n",
            "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.284092\n",
            "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.077910\n",
            "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.184201\n",
            "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.240203\n",
            "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.066580\n",
            "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.218473\n",
            "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.072964\n",
            "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.136040\n",
            "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.157783\n",
            "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.077832\n",
            "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.165669\n",
            "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.271890\n",
            "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.081590\n",
            "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.067967\n",
            "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.077331\n",
            "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.215886\n",
            "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.102279\n",
            "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.333789\n",
            "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.090015\n",
            "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.141249\n",
            "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.220048\n",
            "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.161975\n",
            "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.113497\n",
            "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.243854\n",
            "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.100360\n",
            "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.086300\n",
            "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.284819\n",
            "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.309442\n",
            "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.107539\n",
            "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.091994\n",
            "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.073792\n",
            "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.208891\n",
            "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.181047\n",
            "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.373211\n",
            "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.399346\n",
            "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.123539\n",
            "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.098114\n",
            "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.067759\n",
            "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.259139\n",
            "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.296112\n",
            "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.082835\n",
            "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.307269\n",
            "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.077256\n",
            "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.153384\n",
            "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.256969\n",
            "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.070607\n",
            "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.098098\n",
            "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.133188\n",
            "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.073990\n",
            "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.120631\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0025, Accuracy: 9507/10000 (95%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.249066\n",
            "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.105991\n",
            "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.401356\n",
            "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.116750\n",
            "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.085136\n",
            "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.116469\n",
            "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.082223\n",
            "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.226188\n",
            "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.135205\n",
            "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.086616\n",
            "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.028031\n",
            "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.147122\n",
            "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.092568\n",
            "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.177948\n",
            "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.181979\n",
            "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.055563\n",
            "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.061963\n",
            "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.098284\n",
            "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.123383\n",
            "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.378150\n",
            "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.095522\n",
            "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.233751\n",
            "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.227867\n",
            "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.265352\n",
            "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.177217\n",
            "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.094600\n",
            "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.133815\n",
            "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.223897\n",
            "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.099475\n",
            "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.154832\n",
            "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.070758\n",
            "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.064189\n",
            "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.112382\n",
            "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.146064\n",
            "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.142753\n",
            "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.106863\n",
            "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.058342\n",
            "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.119254\n",
            "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.067711\n",
            "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.182247\n",
            "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.058891\n",
            "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.106291\n",
            "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.207809\n",
            "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.106196\n",
            "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.065972\n",
            "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.358084\n",
            "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.275869\n",
            "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.192540\n",
            "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.067622\n",
            "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.187055\n",
            "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.057910\n",
            "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.205620\n",
            "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.151098\n",
            "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.038587\n",
            "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.199120\n",
            "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.112938\n",
            "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.107340\n",
            "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.114966\n",
            "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.111606\n",
            "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.121882\n",
            "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.080193\n",
            "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.164137\n",
            "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.114806\n",
            "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.107242\n",
            "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.111030\n",
            "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.360635\n",
            "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.151344\n",
            "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.197809\n",
            "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.161707\n",
            "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.166920\n",
            "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.135037\n",
            "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.069803\n",
            "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.237641\n",
            "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.045496\n",
            "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.117706\n",
            "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.209957\n",
            "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.137146\n",
            "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.083500\n",
            "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.062768\n",
            "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.259144\n",
            "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.140117\n",
            "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.148433\n",
            "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.047803\n",
            "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.080909\n",
            "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.111802\n",
            "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.126501\n",
            "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.089815\n",
            "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.063972\n",
            "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.137172\n",
            "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.149136\n",
            "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.132238\n",
            "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.116060\n",
            "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.085409\n",
            "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.085065\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0021, Accuracy: 9589/10000 (96%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.067655\n",
            "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.243979\n",
            "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.089233\n",
            "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.181448\n",
            "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.052184\n",
            "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.153455\n",
            "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.095734\n",
            "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.063227\n",
            "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.087882\n",
            "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.039500\n",
            "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.155276\n",
            "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.090409\n",
            "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.122374\n",
            "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.115703\n",
            "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.074173\n",
            "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.065312\n",
            "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.084496\n",
            "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.207404\n",
            "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.115507\n",
            "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.130054\n",
            "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.139384\n",
            "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.083452\n",
            "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.072705\n",
            "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.151395\n",
            "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.086460\n",
            "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.091931\n",
            "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.171576\n",
            "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.026030\n",
            "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.160886\n",
            "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.267234\n",
            "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.277852\n",
            "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.020055\n",
            "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.188059\n",
            "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.053542\n",
            "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.101670\n",
            "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.036522\n",
            "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.082823\n",
            "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.129157\n",
            "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.088841\n",
            "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.050487\n",
            "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.038844\n",
            "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.120233\n",
            "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.112960\n",
            "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.262782\n",
            "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.029442\n",
            "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.084656\n",
            "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.055040\n",
            "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.119370\n",
            "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.335162\n",
            "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.079938\n",
            "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.134941\n",
            "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.107535\n",
            "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.024431\n",
            "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.035979\n",
            "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.038423\n",
            "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.075154\n",
            "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.063053\n",
            "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.307822\n",
            "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.079150\n",
            "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.229394\n",
            "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.068727\n",
            "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.089154\n",
            "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.143556\n",
            "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.048953\n",
            "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.033048\n",
            "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.061546\n",
            "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.104685\n",
            "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.172615\n",
            "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.161350\n",
            "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.169396\n",
            "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.088905\n",
            "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.048514\n",
            "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.075552\n",
            "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.150733\n",
            "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.200530\n",
            "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.170566\n",
            "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.213556\n",
            "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.072384\n",
            "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.077009\n",
            "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.362295\n",
            "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.156254\n",
            "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.092648\n",
            "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.052287\n",
            "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.159404\n",
            "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.134163\n",
            "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.170859\n",
            "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.041747\n",
            "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.136274\n",
            "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.106532\n",
            "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.044681\n",
            "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.067904\n",
            "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.110591\n",
            "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.189610\n",
            "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.070479\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0018, Accuracy: 9632/10000 (96%)\n",
            "Testing time: 0m 13s\n",
            "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.056790\n",
            "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.115925\n",
            "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.104998\n",
            "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.111836\n",
            "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.021167\n",
            "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.044399\n",
            "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.078433\n",
            "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.063224\n",
            "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.159117\n",
            "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.081454\n",
            "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.037104\n",
            "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.143205\n",
            "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.093112\n",
            "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.062288\n",
            "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.029896\n",
            "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.132180\n",
            "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.036356\n",
            "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.099312\n",
            "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.037989\n",
            "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.105884\n",
            "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.165178\n",
            "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.030866\n",
            "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.105217\n",
            "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.088666\n",
            "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.285631\n",
            "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.207698\n",
            "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.034538\n",
            "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.070549\n",
            "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.169103\n",
            "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.023470\n",
            "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.175909\n",
            "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.143496\n",
            "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.040735\n",
            "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.064809\n",
            "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.047371\n",
            "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.040482\n",
            "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.079932\n",
            "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.085198\n",
            "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.096324\n",
            "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.092423\n",
            "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.067571\n",
            "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.120208\n",
            "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.045751\n",
            "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.093400\n",
            "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.046819\n",
            "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.085862\n",
            "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.088589\n",
            "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.115762\n",
            "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.033471\n",
            "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.085773\n",
            "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.042495\n",
            "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.031022\n",
            "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.049872\n",
            "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.049653\n",
            "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.081943\n",
            "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.193875\n",
            "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.142884\n",
            "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.083222\n",
            "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.031421\n",
            "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.050229\n",
            "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.246246\n",
            "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.017169\n",
            "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.055381\n",
            "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.092788\n",
            "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.095722\n",
            "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.083285\n",
            "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.174118\n",
            "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.052532\n",
            "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.184439\n",
            "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.047164\n",
            "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.028601\n",
            "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.043972\n",
            "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.073508\n",
            "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.024626\n",
            "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.116685\n",
            "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.102246\n",
            "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.208058\n",
            "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.070319\n",
            "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.051705\n",
            "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.149113\n",
            "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.076737\n",
            "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.046173\n",
            "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.185461\n",
            "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.082352\n",
            "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.042903\n",
            "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.058014\n",
            "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.051747\n",
            "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.043174\n",
            "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.220794\n",
            "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.076081\n",
            "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.078180\n",
            "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.185150\n",
            "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.061186\n",
            "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.082371\n",
            "Training time: 0m 12s\n",
            "===========================\n",
            "Test set: Average loss: 0.0017, Accuracy: 9664/10000 (97%)\n",
            "Testing time: 0m 13s\n",
            "Total Time: 1m 55s\n",
            "Model was trained on cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bECp-ANvlOWZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}