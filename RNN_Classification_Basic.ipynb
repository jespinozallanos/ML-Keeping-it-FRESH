{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Classification_Basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOij1uIGI0m6QbTPOoiGJmj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mindyng/ML-Keeping-it-FRESH/blob/master/RNN_Classification_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AApo146l_OwI"
      },
      "source": [
        "This notebook will have example of name classified into certain language. Also, there is introduction to GRU's, transposing vectors, padding when feeding multiple name arrays with various lengths and GPU's (parallelisation) for faster overall computation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0g-xz1S_lYy",
        "outputId": "b08c6589-4f1d-402b-9adb-f109d830b785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Original code is from https://github.com/spro/practical-pytorch\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#from name_dataset import NameDataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# Parameters and DataLoaders\n",
        "HIDDEN_SIZE = 100\n",
        "N_CHARS = 128  # ASCII\n",
        "N_CLASSES = 18\n",
        "\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Note: we run this all at once (over the whole input sequence)\n",
        "\n",
        "        # input = B x S . size(0) = B\n",
        "        batch_size = input.size(0)\n",
        "\n",
        "        # input:  B x S  -- (transpose) --> S x B\n",
        "        input = input.t()\n",
        "\n",
        "        # Embedding S x B -> S x B x I (embedding size)\n",
        "        print(\"  input\", input.size())\n",
        "        embedded = self.embedding(input)\n",
        "        print(\"  embedding\", embedded.size())\n",
        "\n",
        "        # Make a hidden\n",
        "        hidden = self._init_hidden(batch_size)\n",
        "\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        print(\"  gru hidden output\", hidden.size())\n",
        "        # Use the last layer output as FC's input\n",
        "        # No need to unpack, since we are going to use hidden\n",
        "        fc_output = self.fc(hidden)\n",
        "        print(\"  fc output\", fc_output.size())\n",
        "        return fc_output\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
        "        return Variable(hidden)\n",
        "\n",
        "# Help functions\n",
        "\n",
        "\n",
        "def str2ascii_arr(msg):\n",
        "    arr = [ord(c) for c in msg]\n",
        "    return arr, len(arr)\n",
        "\n",
        "# pad sequences and sort the tensor\n",
        "def pad_sequences(vectorized_seqs, seq_lengths):\n",
        "    seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
        "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
        "    return seq_tensor\n",
        "\n",
        "# Create necessary variables, lengths, and target\n",
        "def make_variables(names):\n",
        "    sequence_and_length = [str2ascii_arr(name) for name in names]\n",
        "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
        "    seq_lengths = torch.LongTensor([sl[1] for sl in sequence_and_length])\n",
        "    return pad_sequences(vectorized_seqs, seq_lengths)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    names = ['adylov', 'solan', 'hard', 'san']\n",
        "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_CLASSES)\n",
        "\n",
        "    for name in names:\n",
        "        arr, _ = str2ascii_arr(name)\n",
        "        inp = Variable(torch.LongTensor([arr]))\n",
        "        out = classifier(inp)\n",
        "        print(\"in\", inp.size(), \"out\", out.size())\n",
        "\n",
        "\n",
        "    inputs = make_variables(names)\n",
        "    out = classifier(inputs)\n",
        "    print(\"batch in\", inputs.size(), \"batch out\", out.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  input torch.Size([6, 1])\n",
            "  embedding torch.Size([6, 1, 100])\n",
            "  gru hidden output torch.Size([1, 1, 100])\n",
            "  fc output torch.Size([1, 1, 18])\n",
            "in torch.Size([1, 6]) out torch.Size([1, 1, 18])\n",
            "  input torch.Size([5, 1])\n",
            "  embedding torch.Size([5, 1, 100])\n",
            "  gru hidden output torch.Size([1, 1, 100])\n",
            "  fc output torch.Size([1, 1, 18])\n",
            "in torch.Size([1, 5]) out torch.Size([1, 1, 18])\n",
            "  input torch.Size([4, 1])\n",
            "  embedding torch.Size([4, 1, 100])\n",
            "  gru hidden output torch.Size([1, 1, 100])\n",
            "  fc output torch.Size([1, 1, 18])\n",
            "in torch.Size([1, 4]) out torch.Size([1, 1, 18])\n",
            "  input torch.Size([3, 1])\n",
            "  embedding torch.Size([3, 1, 100])\n",
            "  gru hidden output torch.Size([1, 1, 100])\n",
            "  fc output torch.Size([1, 1, 18])\n",
            "in torch.Size([1, 3]) out torch.Size([1, 1, 18])\n",
            "  input torch.Size([6, 4])\n",
            "  embedding torch.Size([6, 4, 100])\n",
            "  gru hidden output torch.Size([1, 4, 100])\n",
            "  fc output torch.Size([1, 4, 18])\n",
            "batch in torch.Size([4, 6]) batch out torch.Size([1, 4, 18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjZfyqTdGtOF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}